Problem Framing




	qualitative
	quantitative
	question
	Current State
	too much fraud=> bad user experience => less engagement => less revenue
	20% fraud=> 10% less engagement => 10% loss in revenue
	what is the current situation (pains/desires) that we want to address and why?
	Objectives
	* build a model that can block fraudulent transactions as soon as one tries to attempt a fraud
* decrease fraud=> improve user experience => improve user engagement => more revenue => improve topline
	reduce at least half of the fraud payments(from 20% to 10%)  => 5% more engagement => 5% more revenue
	what is that we want to do and why? (to improve topline/bottomline?)
	Benefit/ Cost Tradeoff and Prioratization
	* cost of errors:
FN => fraud occurs but declared not fraud => bad user experience => low engagement => less revenue
FP => genuine message blocked as fraud => very bad user experience => more complaints => moer churn => big loss of revenue
* benefits of correct predictions:
TP => correctly blocked fraud => better user experience => better engagement => more revenue
TN => correctly kept non-fraud => maintained user experience as expected => no significant impact on revenue


	cost-benefit matrix




c(TP)
	c(FP)
	c(FN)
	c(TN)
	



1% TP => + 0.5% engagement => 
+ 0.5% revenue


1% FP => 1% very bad experiences => 0.1% risk of churn => 10% less engagement over customer lifetime  => 10% less revenue


1% FN => -0.5% engagement => -0.5% revenue


1% TN => no significant impact on revenue
	what are the cost of errors/benefits of correct predictions and why?
	Constraints
	can only afford a small FP percent => very small percent of very bad user experience => limited risk of churn => limited loss of revenue




	at most 10% FP => 1% very bad experiences => 0.1% churn => 0.1% risk of revenue loss => acceptable risk for 5% potential upside in revenue
	what are the acceptable risks/budgets and why?
	Desired State
	* benefit: significantly lesser fraud=> significantly better user experience => significantly better engagement => significantly better revenue
* cost: very few false positives => limited risk of very bad user experience => limited risk of churn => limited risk to revenue
	* at least 50% decrease in spam (from 20% to 10%) => 5% better engagement => 5% more revenue
* at most 10% false positives => 1% very bad experiences => 0.1% churns => 0.1% risk to revenue
	what is the desired outcome (benefits/costs) that we want to see and why?
	





Why ML


	qualitative
	quantitative
	question
	best non-ML alternative
hypothesis
	classify based on a curated list of keywords => too many FP and FN => very bad user experience => lesser engagement => loss of revenue
	50% FP 70% FN => not cleaning enough spam and causing more complaints for misplacing genuine sms as spam => 5% revenue loss risk
	what are the non-ML alternatives and why are they problematic? (pains/missed gains)?
	ML value proposition hypothesis
	much fewer FP and FN => much better user experience => much better revenue
	10% FP 50% FN => 50% decrease in spam (from 20% to 10%) at the expense of 1% bad engagements => 5% increase in revenue at the expense of 0.1% risk
	what are the advantages (pain relievers/gain creators) of ML solution and why?
	ML feasibility
hypothesis
	* data: labelled samples of historic sms text data is available
* model: state of the art review suggests promising candidates are available
	* data: around five thousand samples
* model: state of the art claim solutions with 10% FP 20% FN
	what data and model are good candidates and why?
	



ML Solution Design 




	choices
	metrics
	experiment
	data
	(labelled) transaction data
	* label imbalance
	* randomized 70/15/15 train/validation/test split
	model
	pr(fraud)
	* AUCPR
(precision recall curve)
	* rule based heuristic
* tf-idf + logistic regression 
* tf-idf + random forest
* BERT + logistic regression


train these benchmark models (from simpler to more complex) using train data. validate and tune using validation data. select the model with best AUCPR on test data
	action
	if pr(fraud) > threshold: auto take down
	* precision
* recall
* confusion matrix


	* choose a threshold to maximize the recall (estimated reward) subject to precision > 90%
	reward
	* decrease in fraud transactions
* cost of misclassification
	* % decrease in spam
* % increase in daily active users
	* shadow test
* A/B test